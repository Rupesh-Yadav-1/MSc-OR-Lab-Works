{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21i190004_IE684_Lab2_Ex2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r4Hk2Jij4mfR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evalf(x):  \n",
        "  #Input: x is a numpy array of size 3 \n",
        "  assert type(x) is np.ndarray and len(x) == 3 #do not allow arbitrary arguments\n",
        "  #arr=np.array([(1/(8^i))*((x[i-1]-2^i)^2) for i in range(1,4)])\n",
        "  #return np.sum(arr)\n",
        "  return (1/8)*((x[0]-2)**2) + (1/8**2)*((x[1]-2**2)**2) + (1/8**3)*((x[2]-2**3)**2)"
      ],
      "metadata": {
        "id": "5ybxbv3X4_JJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalg(x):  \n",
        "  #Input: x is a numpy array of size 3\n",
        "  assert type(x) is np.ndarray and len(x) == 3 #do not allow arbitrary arguments \n",
        "  \n",
        "  return np.array([(1/4)*(x[0]-2), (1/32)*(x[1]-4), (1/256)*(x[2]-8)])"
      ],
      "metadata": {
        "id": "qoK_qUud6YHb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_steplength_exact(gradf, A):\n",
        "  assert type(gradf) is np.ndarray and len(gradf) == 3 \n",
        "  assert type(A) is np.ndarray and A.shape[0] == 3 and  A.shape[1] == 3 #allow only a 3x3 array\n",
        "   \n",
        "  a_1 =np.linalg.multi_dot([gradf,gradf])\n",
        "  a_22=np.matmul(np.transpose(gradf),A)\n",
        "  a_2 =np.linalg.multi_dot([a_22,gradf])\n",
        "  step_length=a_1/(2*a_2)\n",
        "  \n",
        "  return step_length"
      ],
      "metadata": {
        "id": "P3rhW_3w7nZs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_steplength_backtracking(x, gradf, alpha_start, rho, gamma): \n",
        "  assert type(x) is np.ndarray and len(x) == 3\n",
        "  assert type(gradf) is np.ndarray and len(gradf) == 3 \n",
        "  \n",
        "  alpha = alpha_start\n",
        "  pk=-gradf\n",
        "  while evalf(x+alpha*pk)>evalf(x)+gamma*alpha*np.linalg.multi_dot([gradf,pk]):\n",
        "    alpha=rho*alpha\n",
        "\n",
        "  #print('final step length:',alpha)\n",
        "  return alpha"
      ],
      "metadata": {
        "id": "V7_N6--U78Kd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EXACT_LINE_SEARCH = 1\n",
        "BACKTRACKING_LINE_SEARCH = 2\n",
        "CONSTANT_STEP_LENGTH = 3"
      ],
      "metadata": {
        "id": "gWDY1jww9MAf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minimizer(start_x, tol, line_search_type, *args):\n",
        "  #Input: start_x is a numpy array of size 2, tol denotes the tolerance and is a positive float value\n",
        "  assert type(start_x) is np.ndarray and len(start_x) == 3 #do not allow arbitrary arguments \n",
        "  assert type(tol) is float and tol>=0 \n",
        "  # construct a suitable A matrix for the quadratic function \n",
        "  A = np.array([[1/8,0,0],[0,1/64,0],[0,0,1/512]])\n",
        "  x = start_x\n",
        "  g_x = evalg(x)\n",
        "\n",
        "  #initialization for backtracking line search\n",
        "  if(line_search_type == BACKTRACKING_LINE_SEARCH):\n",
        "    alpha_start = args[0]\n",
        "    rho = args[1]\n",
        "    gamma = args[2]\n",
        "    #print('Params for Backtracking LS: alpha start:', alpha_start, 'rho:', rho,' gamma:', gamma)\n",
        "\n",
        "  k = 0\n",
        "  #print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "\n",
        "  while (np.linalg.norm(g_x) > tol): #continue as long as the norm of gradient is not close to zero upto a tolerance tol\n",
        "  \n",
        "    if line_search_type == EXACT_LINE_SEARCH:\n",
        "      step_length = compute_steplength_exact(g_x, A) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('EXACT LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == BACKTRACKING_LINE_SEARCH:\n",
        "      step_length = compute_steplength_backtracking(x,g_x, alpha_start,rho, gamma) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('BACKTRACKING LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == CONSTANT_STEP_LENGTH: #do a gradient descent with constant step length\n",
        "      step_length = 0.1\n",
        "    else:  \n",
        "      raise ValueError('Line search type unknown. Please check!')\n",
        "    \n",
        "    #implement the gradient descent steps here   \n",
        "    x = np.subtract(x, np.multiply(step_length,g_x)) #update x = x - step_length*g_x\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg(x) #compute gradient at new point\n",
        "\n",
        "    #print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "  return x ,evalf(x), k"
      ],
      "metadata": {
        "id": "u-EzSnzH9Oze"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q 2**"
      ],
      "metadata": {
        "id": "8ZlrXKSFOApC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_start_x = np.array([1,1,1])\n",
        "my_tol= 1e-5\n",
        "\n",
        "print('Using Exact line search:')\n",
        "x_els, obje, itere = find_minimizer(my_start_x, my_tol, EXACT_LINE_SEARCH)\n",
        "print('The minimizer is: ',x_els)\n",
        "print('The minimum function value is: ',obje)\n",
        "print('Number of iterations taken is: ',itere)\n",
        "\n",
        "print('Using Backtracking line search:')\n",
        "x_bls, obj, iter = find_minimizer(my_start_x, my_tol, BACKTRACKING_LINE_SEARCH, 1, 0.5,0.5)\n",
        "print('The minimizer is: ',x_bls)\n",
        "print('The minimum function value is: ',obj)\n",
        "print('Number of iterations taken is: ',iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9XY5NNZJJI1",
        "outputId": "270f5595-1b11-46e8-da1d-ff299c35cb3a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Exact line search:\n",
            "The minimizer is:  [2.00001649 4.         7.99768767]\n",
            "The minimum function value is:  1.0477122031231117e-08\n",
            "Number of iterations taken is:  151\n",
            "Using Backtracking line search:\n",
            "The minimizer is:  [2.         4.         7.99744063]\n",
            "The minimum function value is:  1.2793697352715871e-08\n",
            "Number of iterations taken is:  2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q 3**"
      ],
      "metadata": {
        "id": "99fIf_ReOPuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_start=np.array([1/64,1/8,1])\n",
        "tol=1e-10"
      ],
      "metadata": {
        "id": "AcX_cO2JKKDq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('For Exact line search:')\n",
        "x_bls_1, obj_1, iter_1 = find_minimizer(x_start, tol, EXACT_LINE_SEARCH)\n",
        "print('The minimizer is: ',x_bls_1)\n",
        "print('The minimum function value is: ',obj_1)\n",
        "print('Number of iterations taken is: ',iter_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzYMZ78UOiP1",
        "outputId": "7d808659-2daa-4e81-a4b9-8fd126de3284"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Exact line search:\n",
            "The minimizer is:  [2.         4.         7.99999998]\n",
            "The minimum function value is:  9.150071377581033e-19\n",
            "Number of iterations taken is:  269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('For Backtracking line search:')\n",
        "x_bls_2, obj_2, iter_2 = find_minimizer(x_start, tol, BACKTRACKING_LINE_SEARCH, 1, 0.5,0.5)\n",
        "print('The minimizer is: ',x_bls_2)\n",
        "print('The minimum function value is: ',obj_2)\n",
        "print('Number of iterations taken is: ',iter_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcPjp5udOfpl",
        "outputId": "e701e295-c528-4b1e-99ee-99545e48985e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Backtracking line search:\n",
            "The minimizer is:  [2.         4.         7.99999997]\n",
            "The minimum function value is:  1.2748574165464873e-18\n",
            "Number of iterations taken is:  4964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of iterations taken in case of Exact line search method is far less than that in Backtracking line search case because the Exact line search is always most efficient(if possible to apply)."
      ],
      "metadata": {
        "id": "HSMl85pCUCck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q 4**"
      ],
      "metadata": {
        "id": "7xOsKEgxO-Vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evalf_4(x):  \n",
        "  #Input: x is a numpy array of size 4\n",
        "  assert type(x) is np.ndarray and len(x) == 4 #do not allow arbitrary arguments\n",
        "  #arr=np.array([(1/(8^i))*((x[i-1]-2^i)^2) for i in range(1,4)])\n",
        "  #return np.sum(arr)\n",
        "  return (1/8)*((x[0]-2)**2) + (1/8**2)*((x[1]-2**2)**2) + (1/8**3)*((x[2]-2**3)**2) + (1/8**4)*((x[3]-2**4)**2)"
      ],
      "metadata": {
        "id": "DoGFBMqQPQgf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalg_4(x):  \n",
        "  #Input: x is a numpy array of size 4\n",
        "  assert type(x) is np.ndarray and len(x) == 4 #do not allow arbitrary arguments \n",
        "  \n",
        "  return np.array([(1/8)*(x[0]-2), (1/32)*(x[1]-4), (1/256)*(x[2]-8), (1/2048)*(x[3]-16)])"
      ],
      "metadata": {
        "id": "Tbo4mN9vPWFE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_steplength_exact_4(gradf, A):\n",
        "  assert type(gradf) is np.ndarray and len(gradf) == 4\n",
        "  assert type(A) is np.ndarray and A.shape[0] == 4 and  A.shape[1] == 4 #allow only a 4x4 array\n",
        "   \n",
        "  a_1 =np.linalg.multi_dot([gradf,gradf])\n",
        "  a_22=np.matmul(np.transpose(gradf),A)\n",
        "  a_2 =np.linalg.multi_dot([a_22,gradf])\n",
        "  step_length=a_1/(2*a_2)\n",
        "  \n",
        "  return step_length"
      ],
      "metadata": {
        "id": "QrVtja5eRRyK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_steplength_backtracking_4(x, gradf, alpha_start, rho, gamma): \n",
        "  assert type(x) is np.ndarray and len(x) == 4\n",
        "  assert type(gradf) is np.ndarray and len(gradf) == 4 \n",
        "  \n",
        "  alpha = alpha_start\n",
        "  pk=-gradf\n",
        "  while evalf_4(x+alpha*pk)>evalf_4(x)+gamma*alpha*np.linalg.multi_dot([gradf,pk]):\n",
        "    alpha=rho*alpha\n",
        "\n",
        "  #print('final step length:',alpha)\n",
        "  return alpha"
      ],
      "metadata": {
        "id": "2Z8NnAD_RVTz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minimizer_4(start_x, tol, line_search_type, *args):\n",
        "  #Input: start_x is a numpy array of size 4, tol denotes the tolerance and is a positive float value\n",
        "  assert type(start_x) is np.ndarray and len(start_x) == 4 #do not allow arbitrary arguments \n",
        "  assert type(tol) is float and tol>=0 \n",
        "  # construct a suitable A matrix for the quadratic function\n",
        "  A = np.array([[1/8,0,0,0],[0,1/64,0,0],[0,0,1/512,0],[0,0,0,1/4096]])\n",
        "  x = start_x\n",
        "  g_x = evalg_4(x)\n",
        "\n",
        "  #initialization for backtracking line search\n",
        "  if(line_search_type == BACKTRACKING_LINE_SEARCH):\n",
        "    alpha_start = args[0]\n",
        "    rho = args[1]\n",
        "    gamma = args[2]\n",
        "\n",
        "  k = 0\n",
        "\n",
        "  while (np.linalg.norm(g_x) > tol): #continue as long as the norm of gradient is not close to zero upto a tolerance tol\n",
        "  \n",
        "    if line_search_type == EXACT_LINE_SEARCH:\n",
        "      step_length = compute_steplength_exact_4(g_x, A) #call the new function you wrote to compute the steplength\n",
        "    elif line_search_type == BACKTRACKING_LINE_SEARCH:\n",
        "      step_length = compute_steplength_backtracking_4(x,g_x, alpha_start,rho, gamma) #call the new function you wrote to compute the steplength\n",
        "    elif line_search_type == CONSTANT_STEP_LENGTH: #do a gradient descent with constant step length\n",
        "      step_length = 0.1\n",
        "    else:  \n",
        "      raise ValueError('Line search type unknown. Please check!')\n",
        "    \n",
        "    #implement the gradient descent steps here   \n",
        "    x = np.subtract(x, np.multiply(step_length,g_x)) #update x = x - step_length*g_x\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg_4(x) #compute gradient at new point\n",
        "\n",
        "  return x ,evalf_4(x), k"
      ],
      "metadata": {
        "id": "YUiXolryQ5ir"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_start_4=np.array([1/512,1/64,1/8,1])\n",
        "tol=1e-10"
      ],
      "metadata": {
        "id": "zyu0Rkc6Oy8P"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('For Exact line search:')\n",
        "x_bls_3, obj_3, iter_3 = find_minimizer_4(x_start_4, tol, EXACT_LINE_SEARCH)\n",
        "print('The minimizer is: ',x_bls_3)\n",
        "print('The minimum function value is: ',obj_3)\n",
        "print('Number of iterations taken is: ',iter_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvr-RJ2nPPC4",
        "outputId": "e4cda05d-461b-482b-8d44-39c25a3bbe63"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Exact line search:\n",
            "The minimizer is:  [ 2.          4.          8.         15.99999989]\n",
            "The minimum function value is:  2.7116323920795455e-18\n",
            "Number of iterations taken is:  295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('For Backtracking line search:')\n",
        "x_bls_4, obj_4, iter_4 = find_minimizer_4(x_start_4, tol, BACKTRACKING_LINE_SEARCH, 1, 0.5,0.5)\n",
        "print('The minimizer is: ',x_bls_4)\n",
        "print('The minimum function value is: ',obj_4)\n",
        "print('Number of iterations taken is: ',iter_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6lnrKnfRpU7",
        "outputId": "878fe3be-78f6-47c9-9401-4d6d50a099a0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Backtracking line search:\n",
            "The minimizer is:  [ 2.         4.         8.        15.9999998]\n",
            "The minimum function value is:  1.0237544252113109e-17\n",
            "Number of iterations taken is:  37079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, Exact line search is taking less number of iterations as compared to Backtracking line search.\n",
        "\n",
        "Here the Exact line search method is taking almost same number of iterations as in Exact line search of last ques. But the number of iterations in case of Backtracking line search has increased significantly(almost 10 times) with increase in N."
      ],
      "metadata": {
        "id": "rVDKfLcjUACN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q 5**"
      ],
      "metadata": {
        "id": "-qzMnEThT99U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think for large values of N Backtracking line search method will take very large number of iterations as only increasing N from 3 to 4 resulted in almost 10 times increase in number of iterations. Hence exact line search method will be more efficient."
      ],
      "metadata": {
        "id": "KAZNaqJYT_al"
      }
    }
  ]
}