{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21i190004_IE684_Lab2_Ex1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVE0Xoa0Q5wE"
      },
      "source": [
        "$\\Large\\textbf{Lab 2. Exercise 1. }$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVkab74DJsRL"
      },
      "source": [
        "Recall that we implemented the gradient descent algorithm to solve $\\min_{\\mathbf{x} \\in {\\mathbb{R}}^n} f(\\mathbf{x})$. The main ingredients in the gradient descent iterations are the descent direction $\\mathbf{p}^k$ which is set to $-\\nabla f(\\mathbf{x}^k)$, and the step length $\\eta^k$ which is found by solving an optimization problem (or sometimes taken as a constant value over all iterations). We used the following procedure in the previous lab:\n",
        "\n",
        "\\begin{align}\n",
        "& \\textbf{Input:} \\text{ Starting point $x^0$, Stopping tolerance $\\tau$}  \\\\\n",
        "& \\textbf{Initialize } k=0 \\\\ \n",
        "& \\mathbf{p}^k =-\\nabla f(\\mathbf{x}^k) \\\\ \n",
        "&\\textbf{While } \\| \\mathbf{p}^k \\|_2 > \\tau \\text{ do:}  \\\\   \n",
        "&\\quad \\quad \\eta^k = \\arg\\min_{\\eta\\geq 0} f(\\mathbf{x}^k + \\eta  \\mathbf{p}^k) = \\arg\\min_{\\eta\\geq 0} f(\\mathbf{x}^k - \\eta  \\nabla f(\\mathbf{x}^k)) \\\\\n",
        "&\\quad \\quad \\mathbf{x}^{k+1} = \\mathbf{x}^k + \\eta^k \\mathbf{p}^k = \\mathbf{x}^k - \\eta^k \\nabla f (\\mathbf{x}^k)  \\\\ \n",
        "&\\quad \\quad k = {k+1} \\\\ \n",
        "&\\textbf{End While} \\\\\n",
        "&\\textbf{Output: } \\mathbf{x}^k\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7ivDCuJRP9b"
      },
      "source": [
        "We saw that for particular cases of quadratic functions, a closed form analytical solution for the minimizer of the optimization problem $\\min_{\\eta \\geq 0} f({\\mathbf{x}}^k + \\eta {\\mathbf{p}}^k)$ exists. However finding a closed form expression as a solution to this optimization problem to find a suitable step length might not always be possible. To tackle general situations, we will try to devise a different procedure in this lab. \n",
        "\n",
        "To find the step length, we will use the following property: \n",
        "Suppose a non-zero $\\mathbf{p} \\in {\\mathbb{R}}^n$ is a descent direction at point $\\mathbf{x}$, and let $\\gamma \\in (0,1)$. Then there exists $\\varepsilon >0$ such that  \n",
        "\\begin{align}\n",
        "f(\\mathbf{x}+\\alpha \\mathbf{p}) \\leq f(\\mathbf{x}) + \\gamma \\alpha \\nabla f(\\mathbf{x})^\\top \\mathbf{p}, \\ \\forall \\alpha \\in (0,\\varepsilon].  \n",
        "\\end{align}\n",
        "\n",
        "The step length $\\eta^k$ can be found using a backtracking procedure illustrated below to find appropriate value of $\\varepsilon$.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV6OddaNAmpA"
      },
      "source": [
        "\n",
        "\\begin{align}\n",
        "& \\textbf{Input:}  \\text{ $\\mathbf{x}^k$, $\\mathbf{p}^k$, $\\alpha^0$, $\\rho \\in (0,1)$, $\\gamma \\in (0,1)$ }  \\\\\n",
        "& \\textbf{Initialize } \\alpha=\\alpha^0 \\\\ \n",
        "&\\textbf{While } f(\\mathbf{x}^k + \\alpha \\mathbf{p}^k)   > f(\\mathbf{x}^k) + \\gamma \\alpha \\nabla f(\\mathbf{x}^k)^\\top \\mathbf{p}^k \\text{ do:}  \\\\   \n",
        "&\\quad \\quad \\alpha = \\rho \\alpha  \\\\\n",
        "&\\textbf{End While} \\\\\n",
        "&\\textbf{Output: } \\alpha\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW-xcDISWmGR"
      },
      "source": [
        "In this exercise, we will check if finding the steplength using the backtracking procedure is advantageous for some quadratic functions. In this sample code we consider $f(\\mathbf{x})=f(x_1,x_2) = (x_1-8)^2 + (x_2 + 12)^2$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJq7tIgIRroP"
      },
      "source": [
        "#numpy package will be used for most of our lab exercises. Please have a look at Please have a look at https://numpy.org/doc/stable/ for numpy documentation\n",
        "#we will first import the numpy package and name it as np\n",
        "import numpy as np \n",
        "#Henceforth, we can lazily use np to denote the much longer numpy !! "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZjX2IwOR8_X"
      },
      "source": [
        "#Now we will define a function which will compute and return the function value \n",
        "def evalf(x):  \n",
        "  #Input: x is a numpy array of size 2 \n",
        "  assert type(x) is np.ndarray and len(x) == 2 #do not allow arbitrary arguments \n",
        "  #after checking if the argument is valid, we can compute the objective function value\n",
        "  #compute the function value and return it \n",
        "  return (x[1]+12)**2 + (-8+x[0])**2\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6klpwtDra_I8"
      },
      "source": [
        "#Now we will define a function which will compute and return the gradient value as a numpy array \n",
        "def evalg(x):  \n",
        "  #Input: x is a numpy array of size 2 \n",
        "  assert type(x) is np.ndarray and len(x) == 2 #do not allow arbitrary arguments \n",
        "  #after checking if the argument is valid, we can compute the gradient value\n",
        "  #compute the gradient value and return it \n",
        "  return np.array([2*(x[0]-8), 2*(x[1]+12)])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3blM08V0HOl"
      },
      "source": [
        "#Complete the module to compute the steplength by using the closed-form expression\n",
        "def compute_steplength_exact(gradf, A): #add appropriate arguments to the function \n",
        "  assert type(gradf) is np.ndarray and len(gradf) == 2 \n",
        "  assert type(A) is np.ndarray and A.shape[0] == 2 and  A.shape[1] == 2 #allow only a 2x2 array\n",
        "   \n",
        "  a_1 =np.linalg.multi_dot([gradf,gradf])\n",
        "  a_22=np.matmul(np.transpose(gradf),A)\n",
        "  a_2 =np.linalg.multi_dot([a_22,gradf])\n",
        "  step_length=a_1/(2*a_2)\n",
        "  \n",
        "  return step_length"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGunDYy6Q21S"
      },
      "source": [
        "#Complete the module to compute the steplength by using the backtracking line search\n",
        "def compute_steplength_backtracking(x, gradf, alpha_start, rho, gamma): #add appropriate arguments to the function \n",
        "  assert type(x) is np.ndarray and len(x) == 2 \n",
        "  assert type(gradf) is np.ndarray and len(gradf) == 2 \n",
        "  \n",
        "  alpha = alpha_start\n",
        "  pk=-gradf\n",
        "  while evalf(x+alpha*pk)>evalf(x)+gamma*alpha*np.linalg.multi_dot([gradf,pk]):\n",
        "    alpha=rho*alpha\n",
        "\n",
        "  #print('final step length:',alpha)\n",
        "  return alpha"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaUUdzLtVSCl"
      },
      "source": [
        "#we define the types of line search methods that we have implemented\n",
        "EXACT_LINE_SEARCH = 1\n",
        "BACKTRACKING_LINE_SEARCH = 2\n",
        "CONSTANT_STEP_LENGTH = 3"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SCJdqivdpxx"
      },
      "source": [
        "def find_minimizer(start_x, tol, line_search_type, *args):\n",
        "  #Input: start_x is a numpy array of size 2, tol denotes the tolerance and is a positive float value\n",
        "  assert type(start_x) is np.ndarray and len(start_x) == 2 #do not allow arbitrary arguments \n",
        "  assert type(tol) is float and tol>=0 \n",
        "  # construct a suitable A matrix for the quadratic function \n",
        "  A = np.array([[1, 0],[0,1]])\n",
        "  x = start_x\n",
        "  g_x = evalg(x)\n",
        "\n",
        "  #initialization for backtracking line search\n",
        "  if(line_search_type == BACKTRACKING_LINE_SEARCH):\n",
        "    alpha_start = args[0]\n",
        "    rho = args[1]\n",
        "    gamma = args[2]\n",
        "    print('Params for Backtracking LS: alpha start:', alpha_start, 'rho:', rho,' gamma:', gamma)\n",
        "\n",
        "  k = 0\n",
        "  print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "\n",
        "  while (np.linalg.norm(g_x) > tol): #continue as long as the norm of gradient is not close to zero upto a tolerance tol\n",
        "  \n",
        "    if line_search_type == EXACT_LINE_SEARCH:\n",
        "      step_length = compute_steplength_exact(g_x, A) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('EXACT LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == BACKTRACKING_LINE_SEARCH:\n",
        "      step_length = compute_steplength_backtracking(x,g_x, alpha_start,rho, gamma) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('BACKTRACKING LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == CONSTANT_STEP_LENGTH: #do a gradient descent with constant step length\n",
        "      step_length = 0.1\n",
        "    else:  \n",
        "      raise ValueError('Line search type unknown. Please check!')\n",
        "    \n",
        "    #implement the gradient descent steps here   \n",
        "    x = np.subtract(x, np.multiply(step_length,g_x)) #update x = x - step_length*g_x\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg(x) #compute gradient at new point\n",
        "\n",
        "    print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "  return x \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q 3**"
      ],
      "metadata": {
        "id": "5pMapOk8YnKa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-kHCkbwe-M4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf4fb9a-2208-4171-aca1-7a7a58494357"
      },
      "source": [
        "\n",
        "my_start_x = np.array([1,1])\n",
        "my_tol= 1e-5\n",
        "\n",
        "x_opt = find_minimizer(my_start_x, my_tol, EXACT_LINE_SEARCH)\n",
        "print(x_opt)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 0  x: [1 1]  f(x): 218  grad at x: [-14  26]  gradient norm: 29.5296461204668\n",
            "iter: 1  x: [  8. -12.]  f(x): 0.0  grad at x: [0. 0.]  gradient norm: 0.0\n",
            "[  8. -12.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check what happens when you call find_minimzer using backtracking line search\n",
        "x_opt_bls = find_minimizer(my_start_x, my_tol, BACKTRACKING_LINE_SEARCH, 1, 0.5,0.5)\n",
        "print(x_opt_bls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6nMkHA7WHXH",
        "outputId": "c7c2a338-80e2-4ded-f3c0-9c2b847e5677"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params for Backtracking LS: alpha start: 1 rho: 0.5  gamma: 0.5\n",
            "iter: 0  x: [1 1]  f(x): 218  grad at x: [-14  26]  gradient norm: 29.5296461204668\n",
            "iter: 1  x: [  8. -12.]  f(x): 0.0  grad at x: [0. 0.]  gradient norm: 0.0\n",
            "[  8. -12.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence, minimizer is (8,-12) and minimum obj function value is 0."
      ],
      "metadata": {
        "id": "wQSCaBfcbycN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q 4**"
      ],
      "metadata": {
        "id": "POQFfDgjYr76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_x_4=np.array([25,25])\n",
        "tol_4=1e-12\n",
        "\n",
        "find_minimizer(start_x_4, tol_4, EXACT_LINE_SEARCH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk9cr_arYtr6",
        "outputId": "3f54e4f9-a177-4947-cf10-5826395245b5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 0  x: [25 25]  f(x): 1658  grad at x: [34 74]  gradient norm: 81.43709228600933\n",
            "iter: 1  x: [  8. -12.]  f(x): 0.0  grad at x: [0. 0.]  gradient norm: 0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  8., -12.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_minimizer(start_x_4, tol_4, BACKTRACKING_LINE_SEARCH, 1, 0.5,0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3TSTQU9c7Gy",
        "outputId": "15d41f85-5bdb-4430-b144-8670160e45ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params for Backtracking LS: alpha start: 1 rho: 0.5  gamma: 0.5\n",
            "iter: 0  x: [25 25]  f(x): 1658  grad at x: [34 74]  gradient norm: 81.43709228600933\n",
            "iter: 1  x: [  8. -12.]  f(x): 0.0  grad at x: [0. 0.]  gradient norm: 0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  8., -12.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both methods are taking same(=1) number of iteration."
      ],
      "metadata": {
        "id": "IzmEgZYQdH22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q 5**"
      ],
      "metadata": {
        "id": "VvaGynPhh2sR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#it also gives final minimum value of function and the no of iterations to obtain the result\n",
        "def find_minimizer_modified(start_x, tol, line_search_type, *args):\n",
        "  #Input: start_x is a numpy array of size 2, tol denotes the tolerance and is a positive float value\n",
        "  assert type(start_x) is np.ndarray and len(start_x) == 2 #do not allow arbitrary arguments \n",
        "  assert type(tol) is float and tol>=0 \n",
        "  # construct a suitable A matrix for the quadratic function \n",
        "  A = np.array([[1, 0],[0,1]])\n",
        "  x = start_x\n",
        "  g_x = evalg(x)\n",
        "\n",
        "  #initialization for backtracking line search\n",
        "  if(line_search_type == BACKTRACKING_LINE_SEARCH):\n",
        "    alpha_start = args[0]\n",
        "    rho = args[1]\n",
        "    gamma = args[2]\n",
        "    #print('Params for Backtracking LS: alpha start:', alpha_start, 'rho:', rho,' gamma:', gamma)\n",
        "\n",
        "  k = 0\n",
        "  #print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "\n",
        "  while (np.linalg.norm(g_x) > tol): #continue as long as the norm of gradient is not close to zero upto a tolerance tol\n",
        "  \n",
        "    if line_search_type == EXACT_LINE_SEARCH:\n",
        "      step_length = compute_steplength_exact(g_x, A) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('EXACT LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == BACKTRACKING_LINE_SEARCH:\n",
        "      step_length = compute_steplength_backtracking(x,g_x, alpha_start,rho, gamma) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('BACKTRACKING LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == CONSTANT_STEP_LENGTH: #do a gradient descent with constant step length\n",
        "      step_length = 0.1\n",
        "    else:  \n",
        "      raise ValueError('Line search type unknown. Please check!')\n",
        "    \n",
        "    #implement the gradient descent steps here   \n",
        "    x = np.subtract(x, np.multiply(step_length,g_x)) #update x = x - step_length*g_x\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg(x) #compute gradient at new point\n",
        "\n",
        "    #print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "  return x , evalf(x), k\n"
      ],
      "metadata": {
        "id": "rWbwh2XWieZo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_x_5=np.array([25,25])\n",
        "tol_5=1e-10\n",
        "gamma=0.5\n",
        "rho=0.5\n",
        "alpha=[1,0.9,0.75,0.6,0.5,0.4,0.25,0.1,0.01]"
      ],
      "metadata": {
        "id": "oaJpjlnwh5Fj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#following dictionaries will be used to store minimizer values, final objective values and no of iterations taken\n",
        "minimizer_values={}\n",
        "fun_obj_values={}\n",
        "no_of_iters={}\n",
        "\n",
        "for i in alpha:\n",
        "  minimizer_values[i],fun_obj_values[i],no_of_iters[i]=find_minimizer_modified(start_x_5,tol_5,BACKTRACKING_LINE_SEARCH,i,rho,gamma)"
      ],
      "metadata": {
        "id": "t0-8DFeviTND"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(minimizer_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITrOk5pnoGmL",
        "outputId": "af276443-ccc2-459b-af55-592be8891eab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: array([  8., -12.]), 0.9: array([  8., -12.]), 0.75: array([  8., -12.]), 0.6: array([  8., -12.]), 0.5: array([  8., -12.]), 0.4: array([  8., -12.]), 0.25: array([  8., -12.]), 0.1: array([  8., -12.]), 0.01: array([  8., -12.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fun_obj_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C0GajQaoOYA",
        "outputId": "814a7801-1b1a-4361-d04e-a286f1ba6b80"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 0.0, 0.9: 1.6579714975258972e-21, 0.75: 1.3714654556129199e-21, 0.6: 2.2038291998576117e-21, 0.5: 0.0, 0.4: 1.1393259623274523e-22, 0.25: 1.3714654556129199e-21, 0.1: 2.3972320602008796e-21, 0.01: 2.4523367712209537e-21}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(no_of_iters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r87jg60uoO-t",
        "outputId": "afa4fbc6-744f-451f-f8c8-1dab237dc739"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 1, 0.9: 12, 0.75: 20, 0.6: 30, 0.5: 1, 0.4: 18, 0.25: 40, 0.1: 123, 0.01: 1358}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "vJ-HiY-opeR7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iters=[no_of_iters[i] for i in alpha] #list which contains no of iterations and it will be used to plot the required curve\n",
        "\n",
        "plt.plot(alpha, iters)\n",
        "# naming the x axis\n",
        "plt.xlabel('alpha values')\n",
        "# naming the y axis\n",
        "plt.ylabel('no. of iterations')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "LjBSKWH0ohx9",
        "outputId": "6fbcf30c-9d21-4718-f9b4-9362ff64ff39"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('number of iterations taken with exact line search: ',find_minimizer_modified(start_x_5, tol_5, EXACT_LINE_SEARCH)[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hkw7Y8yxq95N",
        "outputId": "b20b0c7f-fc93-44b8-ca90-2a0a1194bf51"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of iterations taken with exact line search:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For very small alpha(<0.1) the number of iterations is large whereas for alpha between 0.2 and 1 there is not very large difference."
      ],
      "metadata": {
        "id": "ygFyX6c2Ud8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For alpha = 1 and 0.5 both methods are taking same number of iterations and for others Backtracking is taking more number of iterations as compared to Exact line search."
      ],
      "metadata": {
        "id": "eOraZlz_QlYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q 6**"
      ],
      "metadata": {
        "id": "hUffcOIv0Kcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_x_6=np.array([25,25])\n",
        "tol_6=1e-10\n",
        "gamma=0.5\n",
        "alpha=1\n",
        "rho_list=[0.9,0.75,0.6,0.5,0.4,0.25,0.1,0.01]"
      ],
      "metadata": {
        "id": "kaQAm88_0OKx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#following dictionaries will be used to store minimizer values, final objective values and no of iterations taken\n",
        "minimizer_values_6={}\n",
        "fun_obj_values_6={}\n",
        "no_of_iters_6={}\n",
        "\n",
        "for i in rho_list:\n",
        "  minimizer_values_6[i],fun_obj_values_6[i],no_of_iters_6[i]=find_minimizer_modified(start_x_6,tol_6,BACKTRACKING_LINE_SEARCH,alpha,i,gamma)"
      ],
      "metadata": {
        "id": "-q1LzbaP03bT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(minimizer_values_6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCdgYtB11YSW",
        "outputId": "e1aaf71c-209f-4a20-8f2a-2a6374bfecc5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0.9: array([  8., -12.]), 0.75: array([  8., -12.]), 0.6: array([  8., -12.]), 0.5: array([  8., -12.]), 0.4: array([  8., -12.]), 0.25: array([  8., -12.]), 0.1: array([  8., -12.]), 0.01: array([  8., -12.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fun_obj_values_6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58ccm7RU1eeC",
        "outputId": "c06be83b-92d0-4be1-97e3-b3c84ac63d09"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0.9: 4.960536411900771e-22, 0.75: 1.0819468296335504e-21, 0.6: 7.844395544174143e-22, 0.5: 0.0, 0.4: 1.1393259623274523e-22, 0.25: 1.3714654556129199e-21, 0.1: 2.3972320602008796e-21, 0.01: 2.4523367712209537e-21}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(no_of_iters_6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jSFbemt1e_h",
        "outputId": "a8c6d2f8-d4f9-487d-c0e1-f282edf1e84a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0.9: 9, 0.75: 15, 0.6: 22, 0.5: 1, 0.4: 18, 0.25: 40, 0.1: 123, 0.01: 1358}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iters_6=[no_of_iters_6[i] for i in rho_list] #list which contains no of iterations and it will be used to plot the required curve\n",
        "\n",
        "plt.plot(rho_list, iters_6)\n",
        "# naming the x axis\n",
        "plt.xlabel('rho values')\n",
        "# naming the y axis\n",
        "plt.ylabel('no. of iterations')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "a6GxSmw02bT4",
        "outputId": "75369126-c8e6-4bb6-f289-a92eab6f7d8a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('number of iterations taken with exact line search: ',find_minimizer_modified(start_x_6, tol_6, EXACT_LINE_SEARCH)[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty0L8vqd5JDs",
        "outputId": "07c53ec0-0e31-493e-b88e-988c133c7a43"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of iterations taken with exact line search:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For smaller rho the number of iterations is large whereas for rho between 0.2 and 0.9 there is no significant difference.\n",
        "\n",
        "For rho = 0.5 both methods are taking same number of iterations and for others Backtracking is taking more number of iterations as compared to Exact line search."
      ],
      "metadata": {
        "id": "g8Gcb9ocUfY-"
      }
    }
  ]
}