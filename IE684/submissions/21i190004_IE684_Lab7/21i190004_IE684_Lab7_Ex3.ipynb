{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21i190004_IE684_Lab7_Ex3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WvANCEB5KDep"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "np.random.seed(1000)\n",
        "import timeit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Appropriate choice of $f_i^{'s}$ is given in following cell"
      ],
      "metadata": {
        "id": "OWp529xNA6xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evalfi(x, i, lamda):\n",
        "  assert type(x) is np.ndarray  #do not allow arbitrary type arguments \n",
        "  N = A.shape[0]\n",
        "  d = A.shape[1]\n",
        "  A_i = A[i].reshape(d,1)\n",
        "  return (0.5*lamda*np.matmul(x.T,x))/N + (0.5)*(np.matmul(A_i.T,x)-y[i])**2"
      ],
      "metadata": {
        "id": "T8Pqq0ZcKJZv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalf(x, lamda):\n",
        "  assert type(x) is np.ndarray  #do not allow arbitrary type arguments\n",
        "\n",
        "  ret = 0\n",
        "  for i in range(A.shape[0]):\n",
        "    ret = ret + evalfi(x, i, lamda)\n",
        "  \n",
        "  return ret"
      ],
      "metadata": {
        "id": "2awsveALMQWW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Appropriate choice of Gradient, $g_i^{'s}$, is given in following cells"
      ],
      "metadata": {
        "id": "NmlfLGs2BUs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evalgi(x, i, lamda):\n",
        "  assert type(x) is np.ndarray  #do not allow arbitrary type arguments\n",
        "  N = A.shape[0]\n",
        "  d = A.shape[1]\n",
        "  A_i = A[i].reshape(d,1)\n",
        "  return lamda*x/N + np.matmul(A_i, np.matmul(A_i.T,x)-y[i])"
      ],
      "metadata": {
        "id": "p4RXr7jqMKuJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalg(x, lamda):\n",
        "  assert type(x) is np.ndarray\n",
        "  ret = 0\n",
        "  for i in range(A.shape[0]):\n",
        "    ret = ret + evalgi(x, i, lamda)\n",
        "  \n",
        "  return ret"
      ],
      "metadata": {
        "id": "FfuOZf_egLSy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalg(x, i, lamda):\n",
        "  assert type(x) is np.ndarray \n",
        "  N = A.shape[0]\n",
        "  d = A.shape[1]\n",
        "  A_i = np.reshape(A[i], (d, 1))\n",
        "  return np.add(np.reshape(np.matmul(A_i, np.subtract(np.matmul(A[i], x), y[i])), (d,1)), np.multiply(lamda/N, x))"
      ],
      "metadata": {
        "id": "STm-A331r6W9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have taken only $d = 20000$ due to time constraint.\n",
        "\n",
        "Similar thing can be done for other d values."
      ],
      "metadata": {
        "id": "_SpB6pL7xq38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for ALG-LAB7\n",
        "\n",
        "import timeit\n",
        "np.random.seed(1000) #for repeatability\n",
        "\n",
        "ds = [20000]\n",
        "N = 200\n",
        "lambda_reg = 0.001\n",
        "eps = np.random.randn(N,1) #random noise\n",
        "\n",
        "time_for_d = {}\n",
        "Ax_minus_y_norm_sq = {}\n",
        "L2_norm_diff = {}\n",
        "failure_d_list = []\n",
        "\n",
        "for i in ds:\n",
        "  #Create data matrix, label vector\n",
        "  d = i #Consider the dimension which caused failure in the previous experiment\n",
        "  A = np.random.randn(N,d)\n",
        "  #Normalize the columns\n",
        "  for j in range(A.shape[1]):\n",
        "    A[:,j] = A[:,j]/np.linalg.norm(A[:,j])\n",
        "\n",
        "  xorig = np.ones( (d,1) )\n",
        "  y = np.dot(A,xorig) + eps\n",
        "\n",
        "  #initialize the optimization variable to be used in the new algo ALG-LAB8\n",
        "  x = np.zeros((d,1))\n",
        "  epochs = 1e2 #initialize the number of rounds needed to process\n",
        "  t = 1\n",
        "  arr = np.arange(N) #index array\n",
        "\n",
        "  start = timeit.default_timer() #start the timer\n",
        "  for epoch in range(int(epochs)):\n",
        "    np.random.shuffle(arr) #shuffle every epoch\n",
        "    for i in np.nditer(arr): #Pass through the data points\n",
        "      # Update x using x <- x - 1/t * g_i (x)\n",
        "      x = np.subtract(x, (1/t)*evalg(x, i, lambda_reg))\n",
        "      t = t+1\n",
        "      if t>1e4:\n",
        "        t = 1\n",
        "\n",
        "  alglab7time = timeit.default_timer() - start #time is in seconds\n",
        "  x_alglab7 = x\n",
        "\n",
        "  #time_for_d[d] = alglab7time\n",
        "  #Ax_minus_y_norm_sq[d] = (np.linalg.norm(np.matmul(A,x_alglab7) - y))**2\n",
        "  #L2_norm_diff[d] = (np.linalg.norm(x_alglab7 - xorig))**2\n",
        "\n",
        "  print(\"For d = \",d)\n",
        "  print(\"Time taken = \",alglab7time)\n",
        "  print('||Ax* - y||^2 :', (np.linalg.norm(np.subtract(np.matmul(A, x_alglab7), y)))**2)\n",
        "  print('||x* - x_orig||^2 :', (np.linalg.norm(np.subtract(x_alglab7, xorig)))**2)\n",
        "  print('\\n')\n",
        "  #print the time taken, ||Ax_alglab8 - y||^2, ||x_alglab8 - xorig||^2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkmwjWN9X3-j",
        "outputId": "d7d36966-1fee-4e30-c323-e545807cbaa9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For d =  20000\n",
            "Time taken =  5.97101886999917\n",
            "||Ax* - y||^2 : 1527.2172934822286\n",
            "||x* - x_orig||^2 : 19863.653078980104\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_list = [1e4, 5*1e4, 1e5]"
      ],
      "metadata": {
        "id": "it1JoJYgbpK-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for ALG-LAB7\n",
        "\n",
        "import timeit\n",
        "np.random.seed(1000) #for repeatability\n",
        "\n",
        "#ds = [20000,25000,50000,100000,200000,500000,1000000]\n",
        "#ds = [20000]\n",
        "N = 200\n",
        "lambda_reg = 0.001\n",
        "eps = np.random.randn(N,1) #random noise\n",
        "\n",
        "time_for_d = {}\n",
        "Ax_minus_y_norm_sq = {}\n",
        "L2_norm_diff = {}\n",
        "failure_d_list = []\n",
        "\n",
        "for epoc in epoch_list:\n",
        "  #Create data matrix, label vector\n",
        "  d = 20000 #Consider the dimension which caused failure in the previous experiment\n",
        "  A = np.random.randn(N,d)\n",
        "  #Normalize the columns\n",
        "  for j in range(A.shape[1]):\n",
        "    A[:,j] = A[:,j]/np.linalg.norm(A[:,j])\n",
        "\n",
        "  xorig = np.ones( (d,1) )\n",
        "  y = np.dot(A,xorig) + eps\n",
        "\n",
        "  #initialize the optimization variable to be used in the new algo ALG-LAB8\n",
        "  x = np.zeros((d,1))\n",
        "  epochs = epoc #initialize the number of rounds needed to process\n",
        "  t = 1\n",
        "  arr = np.arange(N) #index array\n",
        "\n",
        "  start = timeit.default_timer() #start the timer\n",
        "  for epoch in range(int(epochs)):\n",
        "    np.random.shuffle(arr) #shuffle every epoch\n",
        "    for i in np.nditer(arr): #Pass through the data points\n",
        "      # Update x using x <- x - 1/t * g_i (x)\n",
        "      x = np.subtract(x, (1/t)*evalg(x, i, lambda_reg))\n",
        "      t = t+1\n",
        "      if t>1e4:\n",
        "        t = 1\n",
        "  alglab7time = timeit.default_timer() - start #time is in seconds\n",
        "  x_alglab7 = x\n",
        "\n",
        "  #time_for_d[epoc] = alglab7time\n",
        "  #Ax_minus_y_norm_sq[epoc] = (np.linalg.norm(np.matmul(A,x_alglab7) - y))**2\n",
        "  #L2_norm_diff[epoc] = (np.linalg.norm(x_alglab7 - xorig))**2\n",
        "\n",
        "  print(\"For epoch = \",epoc)\n",
        "  print(\"Time taken = \",alglab7time)\n",
        "  print('||Ax* - y||^2 :', (np.linalg.norm(np.subtract(np.matmul(A, x_alglab7), y)))**2)\n",
        "  print('||x* - x_orig||^2 :', (np.linalg.norm(np.subtract(x_alglab7, xorig)))**2)\n",
        "  print('\\n')\n",
        "  #print the time taken, ||Ax_alglab8 - y||^2, ||x_alglab8 - xorig||^2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENZHvhPcw1Oz",
        "outputId": "f4e290eb-8c7e-45f1-d65f-6c35ea851551"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For epoch =  10000.0\n",
            "Time taken =  544.0592493259992\n",
            "||Ax* - y||^2 : 2.2756687812538717e-06\n",
            "||x* - x_orig||^2 : 19847.919033137703\n",
            "\n",
            "\n",
            "For epoch =  50000.0\n",
            "Time taken =  2765.306233333\n",
            "||Ax* - y||^2 : 3.140109579839133e-05\n",
            "||x* - x_orig||^2 : 19761.337047708017\n",
            "\n",
            "\n",
            "For epoch =  100000.0\n",
            "Time taken =  5455.923002925001\n",
            "||Ax* - y||^2 : 5.413999717292845e-06\n",
            "||x* - x_orig||^2 : 19776.836109097025\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lamda_list = [1000,100,10,1,0.1,0.01,0.001]"
      ],
      "metadata": {
        "id": "798NFQch9oLx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for ALG-LAB7\n",
        "\n",
        "np.random.seed(1000) #for repeatability\n",
        "time_for_d = {}\n",
        "Ax_minus_y_norm_sq = {}\n",
        "L2_norm_diff = {}\n",
        "failure_d_list = []\n",
        "\n",
        "N = 200\n",
        "eps = np.random.randn(N,1) #random noise\n",
        "\n",
        "#Create data matrix, label vector\n",
        "d = 20000 #Consider the dimension which caused failure in the previous experiment\n",
        "A = np.random.randn(N,d)\n",
        "#Normalize the columns\n",
        "for j in range(A.shape[1]):\n",
        "  A[:,j] = A[:,j]/np.linalg.norm(A[:,j])\n",
        "\n",
        "xorig = np.ones( (d,1) )\n",
        "y = np.dot(A,xorig) + eps\n",
        "\n",
        "for lambda_reg in lamda_list:\n",
        "  #initialize the optimization variable to be used in the new algo ALG-LAB8\n",
        "  x = np.zeros((d,1))\n",
        "  epochs = 1e5 #initialize the number of rounds needed to process\n",
        "  t = 1\n",
        "  arr = np.arange(N) #index array\n",
        "  start = timeit.default_timer() #start the timer\n",
        "  for epoch in range(int(epochs)):\n",
        "    np.random.shuffle(arr) #shuffle every epoch\n",
        "    for i in np.nditer(arr): #Pass through the data points\n",
        "      # Update x using x <- x - 1/t * g_i (x)\n",
        "      x = np.subtract(x, (1/t)*evalg(x, i, lambda_reg))\n",
        "      t = t+1\n",
        "      if t>1e4:\n",
        "        t = 1\n",
        "  alglab7time = timeit.default_timer() - start #time is in seconds\n",
        "  x_alglab7 = x\n",
        "\n",
        "  #time_for_d[lambda_reg] = alglab7time\n",
        "  #Ax_minus_y_norm_sq[lambda_reg] = (np.linalg.norm(np.matmul(A,x_alglab7) - y))**2\n",
        "  #L2_norm_diff[lambda_reg] = (np.linalg.norm(x_alglab7 - xorig))**2\n",
        "\n",
        "  print(\"For labmda = \",lambda_reg)\n",
        "  print(\"Time taken = \",alglab7time)\n",
        "  print('||Ax* - y||^2 :', (np.linalg.norm(np.subtract(np.matmul(A, x_alglab7), y)))**2)\n",
        "  print('||x* - x_orig||^2 :', (np.linalg.norm(np.subtract(x_alglab7, xorig)))**2)\n",
        "  print('\\n')\n",
        "  #print the time taken, ||Ax_alglab8 - y||^2, ||x_alglab8 - xorig||^2"
      ],
      "metadata": {
        "id": "KdK35NJ49nF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ALG only eliminates the high RAM ussage problem, but it is still taking time.\n",
        "\n",
        "Increasing the number of epochs the time taken is increasing linearly.\n",
        "\n",
        "Changing the value of lambda does not have much effect on time (i successfuly ran the code before but accidently lost it)."
      ],
      "metadata": {
        "id": "BD1sH8jU_8GC"
      }
    }
  ]
}