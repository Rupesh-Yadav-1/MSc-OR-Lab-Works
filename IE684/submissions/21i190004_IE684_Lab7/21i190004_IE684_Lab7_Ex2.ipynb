{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21i190004_IE684_Lab7_Ex2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FCzGg-XMwgDc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from timeit import default_timer as timer\n",
        "from matplotlib.axis import Axis\n",
        "from tabulate import tabulate\n",
        "import timeit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evalf(x,lamda):\n",
        "  assert type(x) is np.ndarray\n",
        "  fx = np.linalg.norm(np.matmul(A,x) - y)\n",
        "  fx = 0.5*(fx)**2 + 0.5*lamda*np.matmul(x.T,x)\n",
        "\n",
        "  return fx"
      ],
      "metadata": {
        "id": "6K8kXzLlky0x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalg(x,lamda):\n",
        "  assert type(x) is np.ndarray\n",
        "\n",
        "  return np.matmul(A.T, np.matmul(A, x) - y) + lamda*x"
      ],
      "metadata": {
        "id": "_2RoziIhlZnR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalh(x,lamda):\n",
        "  assert type(x) is np.ndarray\n",
        "  d = x.shape[0]\n",
        "  return np.matmul(A.T,A) + lamda*np.identity(d)"
      ],
      "metadata": {
        "id": "Kp8vUB3ds0Rn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_steplength_backtracking_scaled_direction(x, gradf, lamda, direction, alpha_start, rho, gamma):\n",
        "  assert type(x) is np.ndarray\n",
        "  assert type(gradf) is np.ndarray\n",
        "  assert type(direction) is np.ndarray\n",
        "  assert type(alpha_start) is float and alpha_start>=0.\n",
        "  assert type(rho) is float and rho>=0.\n",
        "  assert type(gamma) is float and gamma>=0.\n",
        "  \n",
        "  alpha = alpha_start\n",
        "  while evalf(x+alpha*direction, lamda)>evalf(x, lamda)+gamma*alpha*np.matmul(gradf.T,direction):\n",
        "    alpha=rho*alpha\n",
        "\n",
        "  return alpha"
      ],
      "metadata": {
        "id": "j9wCLciivArR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minimizer_newtons(start_x, tol, lamda, *args):\n",
        "  assert type(start_x) is np.ndarray \n",
        "  assert type(tol) is float and tol>=0 \n",
        "\n",
        "  x = start_x\n",
        "  n = x.shape[0]\n",
        "  g_x = evalg(x, lamda)\n",
        "\n",
        "  x_k_list =[]\n",
        "\n",
        "  alpha_start = args[0]\n",
        "  rho = args[1]\n",
        "  gamma = args[2]\n",
        "\n",
        "  failure = 0\n",
        "  time_start_1 = timer()\n",
        "\n",
        "  k=0\n",
        "  while (np.linalg.norm(g_x) > tol):\n",
        "    D_k = np.linalg.inv(evalh(x, lamda))\n",
        "    p_k = -np.matmul(D_k, g_x)\n",
        "    step_length = compute_steplength_backtracking_scaled_direction(x, g_x, lamda, p_k, alpha_start, rho, gamma)\n",
        "  \n",
        "    x = np.add(x,np.multiply(step_length,p_k))\n",
        "    x_k_list.append(x)\n",
        "    k += 1 \n",
        "    g_x = evalg(x, lamda)\n",
        "\n",
        "    if timer()-time_start_1 > 1200:\n",
        "      failure = 1\n",
        "      break;\n",
        "\n",
        "  return x, failure #, evalf(x,lamda), k, x_k_list"
      ],
      "metadata": {
        "id": "h73Yk1T2s_If"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying Newtons method**"
      ],
      "metadata": {
        "id": "6uHMrDVW_PMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for Newton method\n",
        "import numpy as np\n",
        "np.random.seed(1000) #for repeatability\n",
        "\n",
        "N = 200\n",
        "ds = [1000, 5000, 10000]\n",
        "lambda_reg = 0.001\n",
        "eps = np.random.randn(N,1) #random noise\n",
        "\n",
        "time_for_d = {}\n",
        "Ax_minus_y_norm_sq = {}\n",
        "L2_norm_diff = {}\n",
        "failure_d_list = []\n",
        "\n",
        "#For each value of dimension in the ds array, we will check the behavior of Newton method\n",
        "for i in range(np.size(ds)):\n",
        "  d=ds[i]\n",
        "  A = np.random.randn(N,d)\n",
        "  #Normalize the columns\n",
        "  for j in range(A.shape[1]):\n",
        "    A[:,j] = A[:,j]/np.linalg.norm(A[:,j])\n",
        "\n",
        "  xorig = np.ones((d,1))\n",
        "  y = np.dot(A,xorig) + eps\n",
        "\n",
        "  start = timeit.default_timer()\n",
        "  #call Newton method with A,y,lambda and obtain the optimal solution x_opt\n",
        "  x_opt,fail = find_minimizer_newtons(np.zeros((d,1)), 1e-5, lambda_reg, 0.9, 0.5, 0.5)\n",
        "  newtontime = timeit.default_timer() - start #time is in seconds\n",
        "\n",
        "  if fail == 1:\n",
        "    failure_d_list.append[d]\n",
        "  else:\n",
        "    time_for_d[d] = newtontime\n",
        "    Ax_minus_y_norm_sq[d] = (np.linalg.norm(np.matmul(A,x_opt) - y))**2\n",
        "    L2_norm_diff[d] = (np.linalg.norm(x_opt - xorig))**2\n",
        "\n",
        "  print(\"For d = \",d)\n",
        "  print(\"Time taken = \",newtontime)\n",
        "  print('||Ax* - y||^2 :', (np.linalg.norm(np.subtract(np.matmul(A, x_opt), y)))**2)\n",
        "  print('||x* - x_orig||^2 :', (np.linalg.norm(np.subtract(x_opt, xorig)))**2)\n",
        "  print('\\n')\n",
        "  #print the total time and the L2 norm difference || x_opt - xorig|| for Newton method"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzDQhsep22do",
        "outputId": "04972c19-5bf6-4d92-baf3-13837d9db13e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For d =  1000\n",
            "Time taken =  1.1025540950013237\n",
            "||Ax* - y||^2 : 5.676824554121419e-05\n",
            "||x* - x_orig||^2 : 865.3152937000971\n",
            "\n",
            "\n",
            "For d =  5000\n",
            "Time taken =  94.90821207799854\n",
            "||Ax* - y||^2 : 9.79262950921928e-06\n",
            "||x* - x_orig||^2 : 4783.681693007695\n",
            "\n",
            "\n",
            "For d =  10000\n",
            "Time taken =  674.7822562710007\n",
            "||Ax* - y||^2 : 3.571224214197108e-06\n",
            "||x* - x_orig||^2 : 9829.015751261291\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Failure cases** (memory issue) : $d = 20000, 25000, 50000, 100000, 200000, 500000, 1000000 $\n",
        "\n",
        "(Time issue failure is not observed)"
      ],
      "metadata": {
        "id": "uoMykHnXCdDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying BFGS**"
      ],
      "metadata": {
        "id": "OXt0JPs0yw6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for BFGS method to find the minimizer\n",
        "def find_minimizer_BFGS(start_x, tol, lamda, B_k, *args):\n",
        "  #Input: start_x is a numpy array of size 2, tol denotes the tolerance and is a positive float value\n",
        "  assert type(start_x) is np.ndarray #do not allow arbitrary arguments \n",
        "  assert type(tol) is float and tol>=0 \n",
        "\n",
        "  n = len(start_x)\n",
        "  x = start_x.reshape((n,1))\n",
        "  g_x = evalg(x, lamda)\n",
        "  x_k_list=[]\n",
        "  #initialization for backtracking line search\n",
        "  alpha_start = args[0]\n",
        "  rho = args[1]\n",
        "  gamma = args[2]\n",
        "\n",
        "  failure = 0\n",
        "  time_start_1 = timer()\n",
        "\n",
        "  k=0\n",
        "  while (np.linalg.norm(g_x) > tol):\n",
        "    p_k = -np.matmul(B_k, g_x)\n",
        "    step_length = compute_steplength_backtracking_scaled_direction(x, g_x,lamda, p_k, alpha_start, rho, gamma)\n",
        "\n",
        "    x_k = x\n",
        "    s_k = np.multiply(step_length,p_k)\n",
        "    #x = np.add(x, np.multiply(step_length,p_k)) #update x = x + step_length*direction\n",
        "    x = np.add(x, s_k)#s_k = x - x_k\n",
        "    y_k = evalg(x,lamda)-evalg(x_k, lamda)\n",
        "    s_yT = np.matmul(s_k,y_k.T)\n",
        "    y_sT = np.matmul(y_k, s_k.T)\n",
        "    u_k = 1/(np.matmul(y_k.T,s_k))\n",
        "    term_11 = np.subtract(np.identity(n) , u_k*s_yT)\n",
        "    term_13 = np.subtract(np.identity(n) , u_k*y_sT)\n",
        "    B_k = np.matmul(term_11,np.matmul(B_k,term_13)) + u_k*np.matmul(s_k,s_k.T)\n",
        "    \n",
        "    x_k_list.append(x)\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg(x, lamda) #compute gradient at new point\n",
        "\n",
        "    if timer()-time_start_1 > 1200:\n",
        "      failure = 1\n",
        "      break;    \n",
        "\n",
        "  return x, failure"
      ],
      "metadata": {
        "id": "hEDQl1_Byj6L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for BFGS method\n",
        "np.random.seed(1000) #for repeatability\n",
        "\n",
        "N = 200\n",
        "ds = [1000, 5000, 10000, 20000, 25000, 50000, 100000, 200000, 500000, 1000000]\n",
        "lambda_reg = 0.001\n",
        "eps = np.random.randn(N,1) #random noise\n",
        "\n",
        "time_for_d2 = {}\n",
        "Ax_minus_y_norm_sq2 = {}\n",
        "L2_norm_diff2 = {}\n",
        "failure_d_list2 = []\n",
        "\n",
        "#For each value of dimension in the ds array, we will check the behavior of BFGS method\n",
        "for i in range(np.size(ds)):\n",
        "  d=ds[i]\n",
        "  A = np.random.randn(N,d)\n",
        "  #Normalize the columns\n",
        "  for j in range(A.shape[1]):\n",
        "    A[:,j] = A[:,j]/np.linalg.norm(A[:,j])\n",
        "  xorig = np.ones((d,1))\n",
        "  y = np.dot(A,xorig) + eps\n",
        "  B_k = np.identity(d)/10\n",
        "\n",
        "  start = timeit.default_timer()\n",
        "  #call BFGS method with A,y,lambda and obtain the optimal solution x_opt_bfgs\n",
        "  x_opt,fail = find_minimizer_BFGS(np.zeros((d,1)), 1e-5, lambda_reg, B_k, 0.9, 0.5, 0.5)\n",
        "  bfgstime = timeit.default_timer() - start #time is in seconds\n",
        "\n",
        "  if fail == 1:\n",
        "    failure_d_list2.append(d)\n",
        "    print('d = ',d,'is failure case (runtime exceeded 20 min)')\n",
        "  else:\n",
        "    time_for_d2[d] = bfgstime\n",
        "    Ax_minus_y_norm_sq2[d] = (np.linalg.norm(np.matmul(A,x_opt) - y))**2\n",
        "    L2_norm_diff2[d] = (np.linalg.norm(x_opt - xorig))**2\n",
        "    print(\"For d = \",d)\n",
        "    print(\"Time taken = \",bfgstime)\n",
        "    print('||Ax* - y||^2 :', (np.linalg.norm(np.subtract(np.matmul(A, x_opt), y)))**2)\n",
        "    print('||x* - x_orig||^2 :', (np.linalg.norm(np.subtract(x_opt, xorig)))**2)\n",
        "    print('\\n')\n",
        "    #print the total time, ||Ax_opt_bfgs-y||^2 and the L2 norm difference || x_opt_bfgs -xorig||^2 for BFGS method"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xr86fNJ_1ri",
        "outputId": "2937fc81-6656-495f-9345-40bbdb2fbb34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For d =  1000\n",
            "Time taken =  4.273284377999516\n",
            "||Ax* - y||^2 : 5.6716162511516556e-05\n",
            "||x* - x_orig||^2 : 865.3153037923155\n",
            "\n",
            "\n",
            "For d =  5000\n",
            "Time taken =  293.07926795800086\n",
            "||Ax* - y||^2 : 9.796492582376549e-06\n",
            "||x* - x_orig||^2 : 4783.681692838852\n",
            "\n",
            "\n",
            "d =  10000 is failure case (runtime exceeded 20 min)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Failure cases** (memory issue) : $d = 20000, 25000, 50000, 100000, 200000, 500000, 1000000 $\n",
        "\n",
        "Time failure for $d=10000$"
      ],
      "metadata": {
        "id": "XG3v5-6GlFss"
      }
    }
  ]
}